:

ðŸ“˜ Student Score Prediction

ðŸ“Œ Predicting Student Exam Scores

This project focuses on predicting students' exam scores based on several factors such as study hours, attendance, parental involvement, access to resources, and more.

The dataset used: Student Performance Factors (Kaggle)

ðŸ“ Description

Load and preprocess the dataset

Perform Exploratory Data Analysis (EDA) and visualizations

Handle missing values and outliers

Feature engineering (e.g., log-transforming tutoring sessions)

Train multiple regression models:

Linear Regression

Ridge Regression

Lasso Regression

Evaluate models using RÂ² and RMSE

Compare performance across models

ðŸ›  Tools & Libraries

Python

Pandas â€“ Data handling

NumPy â€“ Numerical operations

Matplotlib / Seaborn â€“ Data visualization

Scikit-learn â€“ Modeling, preprocessing, evaluation

ðŸ“Š Covered Topics

Data Cleaning & Preprocessing

Handling Missing Values & Outliers

Exploratory Data Analysis (EDA)

Feature Engineering

Regression Models (Linear, Ridge, Lasso)

Evaluation Metrics (RMSE, RÂ²)

âš¡ Workflow

Load Dataset
Load StudentPerformanceFactors.csv from Kaggle.

Data Cleaning & Preprocessing

Removed missing values

Fixed exam scores > 100

Applied log transformation on tutoring sessions

EDA (Exploratory Data Analysis)

Visualized distributions of features (Hours_Studied, Attendance, etc.)

Analyzed categorical columns (Parental_Involvement, Access_to_Resources, etc.)

Detected and visualized outliers

Feature Engineering & Selection

Numeric + categorical features separated

Applied One-Hot Encoding to categorical features

Standardized numeric features

Modeling

Linear Regression

Ridge Regression (Î±=0.5)

Lasso Regression (Î±=0.1)

Evaluation
Metrics used:

Root Mean Squared Error (RMSE)

Coefficient of Determination (RÂ²)

ðŸ“ˆ Results
Model	Train RÂ²	Test RÂ²	Test RMSE
Linear Regression	0.673	0.701	2.156
Ridge Regression	â€“	0.701	2.156
Lasso Regression	â€“	0.668	2.273

ðŸ‘‰ Ridge and Linear Regression performed similarly, while Lasso underperformed slightly.

ðŸš€ How to Run

Clone the repository

Install dependencies:

pip install -r requirements.txt


Run the Jupyter Notebook / Colab file

ðŸ“Œ Future Work

Add Polynomial Regression for non-linear patterns

Try ElasticNet Regression (combination of Ridge + Lasso)

Hyperparameter tuning with GridSearchCV

Compare with advanced models (Random Forest, XGBoost)
